import argparse
import torch
from typing import List
import numpy as np
import torch.nn.functional as F
from torchvision import models
from PIL import Image
from torchvision import transforms
import urllib

def str2bool(v):
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

def get_children(model: torch.nn.Module) -> List[torch.nn.Module]:
    # get children form model!
    children = list(model.children())
    flatt_children = []
    if children == []:
        # if model has no children; model is last child! :O
        return [model]
    else:
       # look for children from children... to the last child!
        for child in children:
            if "PackedParams" in child._get_name():
                return [model]
            try:
                flatt_children.extend(get_children(child))
            except TypeError:
                flatt_children.append(get_children(child))
    return flatt_children

def get_layers(model):
    flat_modules = []
    modules = model.modules()
    if modules == []:
        return [model]
    else:
        for m in modules:
            if isinstance(m, torch.nn.Sequential):
                flat_modules.extend(get_layers(m))
            else:
                flat_modules.append(m)
    return flat_modules

def extract_layer(model: torch.nn.Module, layer_type: str, layer_number: int, quantized: bool):

    layers = get_children(model)
    layer_num = 0
    layer_data = {'params': {}}
    sample_input = get_sample_input()
    model.eval()

    def layer_hook_fn(layer, input, output):
        x = input[0].int_repr()
        if "conv" in layer_type:
            x = x.permute(0, 2, 3, 1)
        layer_data['input'] = np.int8(x.numpy())
        bias_scale = input[0].q_scale() * layer.weight().q_per_channel_scales().numpy()
        bias = layer.bias().detach().numpy()
        quantized_tensor = np.around(bias / bias_scale).astype(np.int32)
        quantized_tensor.reshape(-1)
        layer_data['params']['bias'] = quantized_tensor
        wgt = layer.weight().int_repr()
        if "conv" in layer_type:
            wgt = wgt.permute(2, 3, 0, 1)
        else:
            assert "linear" in layer_type
            wgt = wgt.permute(1, 0)
        layer_data['params']['weight'] = wgt.numpy()
        # This is what is generated by PyTorch, for some reason they use int8 outputs
        # layer_data['output'] = torch.round(output[0].dequantize() / output[0].q_scale() + output[0].q_zero_point()).int().unsqueeze(0).detach().numpy()
        tx = input[0].int_repr().detach().int()
        tw = layer.weight().int_repr().int()
        tb = torch.from_numpy(quantized_tensor)
        if "conv" in layer_type:
            out = F.conv2d(tx, tw, bias=tb, stride=layer.stride, padding=layer.padding)
            out = out.permute(0, 2, 3, 1).numpy()
        else:
            out = F.linear(tx, tw, bias=tb).numpy()
        layer_data['output'] = out


    for l in layers:
        if layer_type in l._get_name().lower():
            if layer_num == layer_number:
                # print(dir(l))
                l.register_forward_hook(layer_hook_fn)
                layer_data['layer'] = l
                res = model(sample_input)
                assert 'input' in layer_data
                assert len(layer_data['params']) > 0
                return layer_data
            else:
                layer_num += 1
    raise RuntimeError(f"Unable to find layer {layer_type} in model")

def get_resnet18(quantized, layer_type, layer_number):
    model = models.quantization.resnet18(pretrained=True, quantize=quantized)
    layer_type = layer_type.lower()

    if "2d" in layer_type:
        layer_type = layer_type.replace("2d", "")
    elif "3d" in layer_type:
        layer_type = layer_type.replace("3d", "")
    return extract_layer(model, layer_type, layer_number, quantized), model


def get_resnet50(quantized, layer_type, layer_number):
    model = models.quantization.resnet50(pretrained=True, quantized=quantized)
    return extract_layer(model, layer_type.lower(), layer_number, quantized), model



def get_sample_input():
    import urllib
    url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")
    try:
        urllib.URLopener().retrieve(url, filename)
    except:
        urllib.request.urlretrieve(url, filename)

    ## Preprocess image
    input_image = Image.open(filename)
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    input_tensor = preprocess(input_image)
    input_batch = input_tensor.unsqueeze(0)
    return input_batch

if __name__ == "__main__":

    layer_data, model = get_resnet18(True, "Conv2D", 0)
    # layer_data, model = get_resnet18(True, "Linear", 0)
    # print(model)
    # print(layer_data['output'][0][0][0])
    # print(f"affter")
    # print(layer_data['output'].dequantize()[0][0][0])
    # out_i32 = torch.round(layer_data['output'].dequantize()/layer_data['output'].q_scale() + layer_data['output'].q_zero_point()).int().unsqueeze(0)
    # out_i32 = torch.round(layer_data['output'].dequantize()/layer_data['output'].q_scale() + layer_data['output'].q_zero_point()).int().unsqueeze(0)
    # print(dir(layer_data['output']))

    # print(out_i32[0][0][0])
    # print(f"pytorch res")
    # print(o[0][0][0])
    # torch.testing.assert_allclose(out_i32, o)
    # print(o[0][0][0])
    # print(out_i32[0][0][0])
    # torch.allclose(o, )

    # argparser = argparse.ArgumentParser(description='PyTorch Model Weight Extractor')
    # argparser.add_argument('-m', '--model_name', required=True,
    #                        help='Name of the benchmark to create. One of "resnet18", "lenet')
    # argparser.add_argument('-q', '--quantized', type=str2bool, nargs='?', default=True,
    #                        const=True, help='Whether or not to retreive a quantized model')
    # argparser.add_argument('-l', '--layer_id', required=True, help='The layer type to extract from the model')
    # argparser.add_argument('-ln', '--layer_number', type=int, default=0, help='The nth layer of type "layer-type" '
    #                                                                           'to extract. Default is 0.')
    # args = argparser.parse_args()

    # layer_data, model = get_resnet18(True, "Conv2D", 0)


    # if args.model_name == "resnet18":
    #     _ = get_resnet18(args.quantized, args.layer_id, args.layer_number)
    # elif args.model_name == "resnet50":
    #     _ = get_resnet50(args.quantized, args.layer_id, args.layer_number)
    # raise RuntimeError(f"Model {args.model_name} is not currently supported")